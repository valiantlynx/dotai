{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee9c2e3-d844-469d-a044-9df3c81a410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import dump, load\n",
    "import os\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    filename=\"data_loading_errors.log\",\n",
    "    level=logging.WARNING,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "# Paths\n",
    "zip_path = \"data/dota_games.zip\"\n",
    "heroes_json_path = \"data/heroes.json\"\n",
    "games_to_process = None  # Process all games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30560cb-bf6a-47c8-9bff-86e7e372f95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded hero mappings: 122\n"
     ]
    }
   ],
   "source": [
    "def load_hero_names(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        heroes = json.load(f)\n",
    "    return {hero[\"id\"]: hero[\"api_name\"] for hero in heroes}\n",
    "\n",
    "hero_mapping = load_hero_names(heroes_json_path)\n",
    "print(\"Loaded hero mappings:\", len(hero_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc113c9c-5ca3-4fc4-b8d4-c9176e692d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Games:  49%|████████████████████████████▉                              | 1144853/2338043 [05:31<04:58, 3995.34it/s]"
     ]
    }
   ],
   "source": [
    "def load_games(zip_path, games_to_process=None):\n",
    "    X, y = [], []\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_file:\n",
    "        json_files = [name for name in zip_file.namelist() if name.endswith(\".json\")]\n",
    "        if games_to_process:\n",
    "            json_files = json_files[:games_to_process]\n",
    "\n",
    "        for file_name in tqdm(json_files, desc=\"Loading Games\"):\n",
    "            try:\n",
    "                with zip_file.open(file_name, \"r\") as f:\n",
    "                    game_data = json.load(f)\n",
    "\n",
    "                    # Game result features\n",
    "                    game_features = {\n",
    "                        \"radiant_score\": game_data[\"result\"][\"radiant_score\"],\n",
    "                        \"dire_score\": game_data[\"result\"][\"dire_score\"],\n",
    "                        \"duration\": game_data[\"result\"][\"duration\"],\n",
    "                        \"tower_status_radiant\": game_data[\"result\"][\"tower_status_radiant\"],\n",
    "                        \"tower_status_dire\": game_data[\"result\"][\"tower_status_dire\"]\n",
    "                    }\n",
    "\n",
    "                    # Player-level statistics\n",
    "                    for player in game_data[\"result\"][\"players\"]:\n",
    "                        hero_id = player[\"hero_id\"]\n",
    "                        kda = (player[\"kills\"] + player[\"assists\"]) / max(1, player[\"deaths\"])  # KDA metric\n",
    "                        player_features = {\n",
    "                            \"hero_id\": hero_id,\n",
    "                            \"kda\": kda,\n",
    "                            \"gpm\": player[\"gold_per_min\"],\n",
    "                            \"xpm\": player[\"xp_per_min\"],\n",
    "                            \"last_hits\": player[\"last_hits\"],\n",
    "                            \"hero_damage\": player[\"hero_damage\"],\n",
    "                            \"tower_damage\": player[\"tower_damage\"],\n",
    "                            \"hero_healing\": player[\"hero_healing\"]\n",
    "                        }\n",
    "                        combined_features = {**game_features, **player_features}\n",
    "                        X.append(combined_features)\n",
    "                        y.append(1 if game_data[\"result\"][\"radiant_win\"] else 0)\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Error processing file {file_name}: {e}\")\n",
    "    return X, y\n",
    "\n",
    "X_raw, y = load_games(zip_path, games_to_process)\n",
    "print(\"Loaded game data!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f08536d-fc11-495a-8c82-89491de9e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.DataFrame(X_raw).fillna(0)\n",
    "X = df_X.drop(columns=[\"hero_id\"]).values  # Exclude hero_id for training\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"Processed data shape: {X.shape}, Target shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a4bf9-3b32-4cba-aae8-7e255c8e0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "class ManualLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, epochs=500):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = 0\n",
    "        self.loss_history = []\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        m = len(y_true)\n",
    "        loss = -np.mean(y_true * np.log(y_pred + 1e-9) + (1 - y_true) * np.log(1 - y_pred + 1e-9))\n",
    "        return loss\n",
    "\n",
    "    def train(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for epoch in tqdm(range(self.epochs), desc=\"Training Model\"):\n",
    "            # Compute predictions\n",
    "            linear_pred = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = self.sigmoid(linear_pred)\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = np.dot(X.T, (y_pred - y)) / n_samples\n",
    "            db = np.sum(y_pred - y) / n_samples\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "            # Compute loss\n",
    "            loss = self.compute_loss(y, y_pred)\n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "            # Print loss periodically\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        linear_pred = np.dot(X, self.weights) + self.bias\n",
    "        return self.sigmoid(linear_pred)\n",
    "\n",
    "    def predict(self, X):\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return [1 if p > 0.5 else 0 for p in probabilities]\n",
    "\n",
    "    def save_model(self, feature_columns, accuracy):\n",
    "        \"\"\"Save the model with epoch, loss, and accuracy details.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "        filename = f\"manual_logreg_acc{accuracy:.2f}_epochs{self.epochs}_{timestamp}.joblib\"\n",
    "        model_data = {\n",
    "            \"weights\": self.weights,\n",
    "            \"bias\": self.bias,\n",
    "            \"columns\": feature_columns,\n",
    "            \"loss_history\": self.loss_history\n",
    "        }\n",
    "        joblib.dump(model_data, filename)\n",
    "        print(f\"Model saved as: {filename}\")\n",
    "        return filename\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(filename):\n",
    "        \"\"\"Load a saved model.\"\"\"\n",
    "        model_data = joblib.load(filename)\n",
    "        model = ManualLogisticRegression()\n",
    "        model.weights = model_data[\"weights\"]\n",
    "        model.bias = model_data[\"bias\"]\n",
    "        model.loss_history = model_data[\"loss_history\"]\n",
    "        print(f\"Model loaded from: {filename}\")\n",
    "        return model, model_data[\"columns\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41a571-95d0-4b9e-aac8-2ccb81437175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_next_hero_with_roles(model, radiant_heroes, dire_heroes, feature_columns, hero_mapping, chosen_heroes=set()):\n",
    "    roles = {\"Hard Carry\": [], \"Core\": [], \"Support\": []}\n",
    "    hero_probabilities = []\n",
    "\n",
    "    # Predict win probabilities for all available heroes\n",
    "    available_heroes = set(hero_mapping.keys()) - set(radiant_heroes) - set(dire_heroes) - chosen_heroes\n",
    "    for hero_id in available_heroes:\n",
    "        test_radiant = radiant_heroes + [hero_id]\n",
    "        win_prob = predict_win_probability(model, test_radiant, dire_heroes, feature_columns)\n",
    "        hero_probabilities.append((hero_id, win_prob))\n",
    "\n",
    "    # Sort heroes by win probability\n",
    "    hero_probabilities = sorted(hero_probabilities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Assign heroes to roles\n",
    "    for hero_id, win_prob in hero_probabilities:\n",
    "        if \"carry\" in hero_mapping[hero_id].lower():\n",
    "            roles[\"Hard Carry\"].append((hero_id, win_prob))\n",
    "        elif \"support\" in hero_mapping[hero_id].lower():\n",
    "            roles[\"Support\"].append((hero_id, win_prob))\n",
    "        else:\n",
    "            roles[\"Core\"].append((hero_id, win_prob))\n",
    "\n",
    "    # Return best hero per role\n",
    "    best_heroes = {}\n",
    "    for role, heroes in roles.items():\n",
    "        if heroes:\n",
    "            best_heroes[role] = heroes[0]\n",
    "            chosen_heroes.add(heroes[0][0])  # Add to chosen heroes\n",
    "\n",
    "    return best_heroes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4aa3d-eb9b-44d7-a732-784818c5a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = ManualLogisticRegression(learning_rate=0.01, epochs=500)\n",
    "model.train(X, y)\n",
    "\n",
    "# Calculate training accuracy\n",
    "y_pred = model.predict(X)\n",
    "accuracy = np.mean(y == y_pred)\n",
    "print(f\"Training Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Save the model\n",
    "model_filename = model.save_model(df_X.columns, accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951ed8e4-b361-4d35-b979-1828db56069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model, feature_columns = ManualLogisticRegression.load_model(model_filename)\n",
    "\n",
    "# Predict win probability for a new draft\n",
    "radiant_heroes = [7, 9, 44]\n",
    "dire_heroes = [8, 4, 129]\n",
    "\n",
    "def predict_win_probability(model, radiant_heroes, dire_heroes, feature_columns):\n",
    "    draft = {f\"hero_{hero_id}\": 1 for hero_id in radiant_heroes}\n",
    "    draft.update({f\"hero_{hero_id}\": -1 for hero_id in dire_heroes})\n",
    "    draft_df = pd.DataFrame([draft]).reindex(columns=feature_columns, fill_value=0)\n",
    "    return model.predict_proba(draft_df.values)[0]\n",
    "\n",
    "win_prob = predict_win_probability(loaded_model, radiant_heroes, dire_heroes, feature_columns)\n",
    "print(f\"Win Probability for Radiant: {win_prob:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
